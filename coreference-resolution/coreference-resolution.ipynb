{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution\n",
    "\n",
    "Problem: given a set of candidate mentions in a document, which is a correct antecedent for each pronoun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to import any tool for this exercise\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(entity_id, ix_to_entity_id, entity_id_to_ix, sequence_flag=False):\n",
    "    \"\"\"\n",
    "    This function generates the mapping between entity and test ids\n",
    "    This function was used to produce the test ids, and need not be\n",
    "    used for this assignment\n",
    "\n",
    "    :param entity_id: Current entity id\n",
    "    :param ix_to_entity_id: Current mapping from test to entity\n",
    "    :param entity_id_to_ix: Current mappings from entity to test ids\n",
    "    :param sequence_flag: Whether the previous word was the same entity\n",
    "    :return: The test_id for the word\n",
    "    \"\"\"\n",
    "    # If sequence, don't generate new id\n",
    "    if sequence_flag:\n",
    "        cur_ix = entity_id_to_ix[entity_id]\n",
    "        ix = max(cur_ix)\n",
    "        return ix, ix_to_entity_id, entity_id_to_ix\n",
    "    # If existing entity, add to test id list for entity\n",
    "    if entity_id in entity_id_to_ix.keys():\n",
    "        cur_ix = entity_id_to_ix[entity_id]\n",
    "        ix = max(list(ix_to_entity_id.keys())) + 1\n",
    "        cur_ix.append(ix)\n",
    "        entity_id_to_ix[entity_id] = cur_ix\n",
    "        ix_to_entity_id[ix] = entity_id\n",
    "        return ix, ix_to_entity_id, entity_id_to_ix\n",
    "    # Else, create new entry for entity\n",
    "    else:\n",
    "        # If no entry has been created\n",
    "        if len(ix_to_entity_id.keys()) == 0:\n",
    "            ix = -1\n",
    "        else:\n",
    "            ix = max(list(ix_to_entity_id.keys()))\n",
    "        ix_to_entity_id[ix + 1] = entity_id\n",
    "        entity_id_to_ix[entity_id] = [ix + 1]\n",
    "        return ix + 1, ix_to_entity_id, entity_id_to_ix\n",
    "\n",
    "\n",
    "def get_mention_ids(df, return_ds=False):\n",
    "    df.reset_index(inplace=True, drop=\"Index\")\n",
    "\n",
    "    ix_to_entity_id = {}\n",
    "    entity_id_to_ix = {}\n",
    "\n",
    "    prev_entities = []\n",
    "    mention_ids = []\n",
    "\n",
    "    for row_ix in df.index:\n",
    "        label = df[\"entity_ids\"][row_ix]\n",
    "        if pd.isnull(label):\n",
    "            prev_entities = []\n",
    "            mention_ids.append(\"\")\n",
    "            continue\n",
    "        else:\n",
    "            entities = label.split(\" \")\n",
    "            indices = []\n",
    "            for entity in entities:\n",
    "                if entity in prev_entities:\n",
    "                    ix, ix_to_entity_id, entity_id_to_ix = get_index(entity,\n",
    "                                                             ix_to_entity_id,\n",
    "                                                             entity_id_to_ix,\n",
    "                                                             True)\n",
    "                    indices.append(ix)\n",
    "                else:\n",
    "                    ix, ix_to_entity_id, entity_id_to_ix = get_index(entity,\n",
    "                                                             ix_to_entity_id,\n",
    "                                                             entity_id_to_ix)\n",
    "                    indices.append(ix)\n",
    "            mention_ids.append(replace_indices(indices))\n",
    "            prev_entities = entities\n",
    "\n",
    "    if return_ds:\n",
    "        return ix_to_entity_id, entity_id_to_ix\n",
    "    else:\n",
    "        df[\"mention_ids\"] = pd.Series(mention_ids)\n",
    "        return df\n",
    "\n",
    "#################################################\n",
    "# ================ ACCURACY METRIC ==============\n",
    "#################################################\n",
    "\n",
    "\n",
    "def check_common_preds(y_pred, y, ix_to_label):\n",
    "    y_pred = set([ix_to_label[int(pred)] for pred in y_pred.split(\" \")])\n",
    "    y = set(y.split(\" \"))\n",
    "\n",
    "    return len(y.intersection(y_pred)) > 0\n",
    "\n",
    "\n",
    "def check_valid_record(df, y_pred, ix):\n",
    "    r1 = df[\"entity_ids\"][ix]\n",
    "    r2 = y_pred[ix]\n",
    "    pos = df[\"pos\"][ix]\n",
    "\n",
    "    prediction_limit = 3\n",
    "\n",
    "    # Check conditions for valid prediction record\n",
    "    if pd.isnull(r1) or pd.isnull(r2):\n",
    "        return False\n",
    "    if r1 == \"\" or r2 == \"\":\n",
    "        return False\n",
    "    if r1 is None or r2 is None:\n",
    "        return False\n",
    "    if r1 == \"None\" or r2 == \"None\":\n",
    "        return False\n",
    "    if \"PRP\" not in pos:\n",
    "        return False\n",
    "    if len(r2.split(\" \")) > prediction_limit:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def check_accuracy(y_pred, df):\n",
    "    \"\"\"\n",
    "    :param y_pred: pandas series for predicted mention_ids\n",
    "    :param df: The data frame with original entity and mention ids\n",
    "    :return: float: mean accuracy of the predictions\n",
    "    \"\"\"\n",
    "    y = df[\"entity_ids\"].copy()\n",
    "\n",
    "    # build test_id to entity dictionaries and vice versa\n",
    "    ix_to_label, label_to_ix = get_mention_ids(df, True)\n",
    "    scores = []\n",
    "\n",
    "    for ix in y_pred.index:\n",
    "        if check_valid_record(df, y_pred, ix):\n",
    "            scores.append(1.0 if check_common_preds(y_pred[ix], y[ix], ix_to_label)\n",
    "                          else 0.0)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive solution: directly selecting the previous antecedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_resolver(df):\n",
    "    \"\"\"\n",
    "    :param df: The dataframe\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for ix in df[df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(df[\"mention_ids\"][ix]) and \"PRP\" in df[\"pos\"][ix]:\n",
    "            df.at[ix, \"mention_ids\"] = str(\n",
    "                get_closest_prev_antecedent(df[\"mention_ids\"], ix))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_closest_prev_antecedent(d, ix, threshold=100):\n",
    "    \"\"\"\n",
    "    :param d: dataframe for the data\n",
    "    :param ix: current row index\n",
    "    :param threshold: how far back should we check\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    distance = 1\n",
    "\n",
    "    while distance < threshold:\n",
    "        if pd.isnull(d[ix - distance]):\n",
    "            distance += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Splitting the columns with multiple labels\n",
    "            # with a space.\n",
    "            options = str(d[ix - distance]).split(\" \")\n",
    "\n",
    "            # Randomly choose between the possible options\n",
    "            ch = choice(options)\n",
    "            return str(ch)\n",
    "\n",
    "\n",
    "def replace_indices(indices):\n",
    "    return str(indices)[1:-1].replace(\", \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning solution: learn a classifier to predict coreferent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_last_mentions(d, ix, threshold=50):\n",
    "    \"\"\"\n",
    "    :param d: dataframe for the data\n",
    "    :param ix: current row index\n",
    "    :param threshold: how far back should we check\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lst = set()\n",
    "    \n",
    "    distance = 0\n",
    "\n",
    "    while distance < threshold:\n",
    "        if (ix - distance) < 0 or pd.isnull(d[\"mention_ids\"][ix - distance]):\n",
    "            distance += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Splitting the columns with multiple labels\n",
    "            # with a space.\n",
    "            options = str(d[\"mention_ids\"][ix - distance]).split(\" \")\n",
    "            options_entity = str(d[\"entity_ids\"][ix - distance]).split(\" \")\n",
    "            \n",
    "            for i in options:\n",
    "                for j in options_entity:\n",
    "                    if (i == 'None'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        lst.add((i, j))\n",
    "            \n",
    "            distance += 1\n",
    "            \n",
    "    return list(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df):\n",
    "    lst_all = []\n",
    "    lst_matching = []\n",
    "\n",
    "    for ix in df[df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(df[\"mention_ids\"][ix]) and \"PRP\" in df[\"pos\"][ix]:\n",
    "            mention_id_options = df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            entity_id_options = df[\"entity_ids\"].iloc[ix].split(\" \")\n",
    "\n",
    "            for i in mention_id_options:\n",
    "                for j in entity_id_options:\n",
    "                    if (i == 'None'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        mention_id = int(i)\n",
    "                        entity_id = j\n",
    "\n",
    "                        for k in (ret_last_mentions(df[[\"mention_ids\", \"entity_ids\"]], ix)):\n",
    "                            other_mention_id = int(k[0])\n",
    "\n",
    "                            if mention_id != other_mention_id and ([mention_id, other_mention_id] not in lst_all):\n",
    "                                lst_all.append([mention_id, other_mention_id])\n",
    "                            if mention_id != other_mention_id and entity_id == k[1] and ([mention_id, other_mention_id] not in lst_matching):\n",
    "                                lst_matching.append([mention_id, other_mention_id])\n",
    "\n",
    "    alls = np.array(lst_all)\n",
    "    matching = np.array(lst_matching)\n",
    "    labels = np.zeros((alls.shape[0]))\n",
    "\n",
    "    for i in range(len(lst_all)):\n",
    "        if lst_all[i] in lst_matching:\n",
    "            labels[i] = 1\n",
    "            \n",
    "    return alls, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_last_mentions_no_entity(d, ix, threshold=50):\n",
    "    \"\"\"\n",
    "    :param d: dataframe for the data\n",
    "    :param ix: current row index\n",
    "    :param threshold: how far back should we check\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lst = set()\n",
    "    \n",
    "    distance = 0\n",
    "\n",
    "    while distance < threshold:\n",
    "        if (ix - distance) < 0 or pd.isnull(d[ix - distance]):\n",
    "            distance += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Splitting the columns with multiple labels\n",
    "            # with a space.\n",
    "            options = str(d[ix - distance]).split(\" \")\n",
    "            \n",
    "            for i in options:\n",
    "                if (i == 'None'):\n",
    "                    continue\n",
    "                else:\n",
    "                    lst.add(i)\n",
    "            \n",
    "            distance += 1\n",
    "            \n",
    "    return list(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(df):\n",
    "    lst_all = []\n",
    "    for ix in df[df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(df[\"mention_ids\"][ix]) and \"PRP\" in df[\"pos\"][ix]:\n",
    "            mention_id_options = df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "\n",
    "            for i in mention_id_options:\n",
    "                if (i == 'None'):\n",
    "                    continue\n",
    "                else:\n",
    "                    mention_id = int(i)\n",
    "\n",
    "                    for k in (ret_last_mentions_no_entity(df[\"mention_ids\"], ix)):\n",
    "                        other_mention_id = int(k)\n",
    "\n",
    "                        if mention_id != other_mention_id and ([mention_id, other_mention_id] not in lst_all):\n",
    "                            lst_all.append([mention_id, other_mention_id])\n",
    "\n",
    "    alls = np.array(lst_all)\n",
    "            \n",
    "    return alls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    Y_pred = logreg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.5653\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.coref.data.txt\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"dev.coref.data.txt\", sep=\"\\t\")\n",
    "\n",
    "# This modifies the dataframe in place. If your function\n",
    "# writes to a new file, you could read the data to pass it\n",
    "# to check_accuracy in a data frame.\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New text prediction to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_resolver_2(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    Y_pred = logreg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    test_df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.coref.data.txt\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"dev.coref.data.txt\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"test.coref.data.txt\", sep=\"\\t\")\n",
    "\n",
    "# This modifies the dataframe in place. If your function\n",
    "# writes to a new file, you could read the data to pass it\n",
    "# to check_accuracy in a data frame.\n",
    "result_df = better_resolver_2(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"test_predictions.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying other machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bays\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier #stochastic gradient descent\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.5653\n"
     ]
    }
   ],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    Y_pred = logreg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.4344\n"
     ]
    }
   ],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    svc = SVC(probability=True)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    Y_pred = svc.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.3885\n"
     ]
    }
   ],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.3378\n"
     ]
    }
   ],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    gradboost = xgb.XGBClassifier(n_estimators=1000)\n",
    "    gradboost.fit(X_train, Y_train)\n",
    "    Y_pred = gradboost.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 0.3773\n"
     ]
    }
   ],
   "source": [
    "def better_resolver(train_df, test_df):\n",
    "    sln = {}\n",
    "    X_train, Y_train = get_train_test(train_df)\n",
    "    X_test = get_train(test_df)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['mention_ids'])\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=1000)\n",
    "    random_forest.fit(X_train, Y_train)\n",
    "    Y_pred = random_forest.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if Y_pred[i] > .50:\n",
    "            val = X_test[i]\n",
    "            sln[val[0]] = str(val[1])\n",
    "    \n",
    "    for ix in test_df[test_df.pos.str.contains(\"PRP\")].pos.index:\n",
    "        if pd.notnull(test_df[\"mention_ids\"][ix]) and \"PRP\" in test_df[\"pos\"][ix]:\n",
    "            mention_id_options = test_df[\"mention_ids\"].iloc[ix].split(\" \")\n",
    "            for j in mention_id_options:\n",
    "                mention_id = int(j)\n",
    "                if (mention_id in sln.keys()):\n",
    "                    df.at[ix, \"mention_ids\"] = sln[mention_id]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = better_resolver(train_df, dev_df)[\"mention_ids\"]\n",
    "print(\"Accuracy of Model: {:.4f}\".format(check_accuracy(result_df, dev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
